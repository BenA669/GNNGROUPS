import matplotlib.pyplot as plt

# training_loss = [0.24155090749263763, 0.212360218167305, 0.18935802578926086, 0.17655667662620544, 0.16527226567268372, 0.15504737198352814, 0.1540406048297882, 0.14431490004062653, 0.14506332576274872, 0.13608910143375397, 0.13607119023799896, 0.13531266152858734, 0.13292698562145233, 0.13405239582061768, 0.1280486136674881, 0.1324818730354309, 0.13032129406929016, 0.1277799755334854, 0.12137772887945175, 0.12195662409067154, 0.11436563730239868, 0.12214318662881851, 0.1167915090918541, 0.10933399200439453, 0.12075664848089218, 0.11035781353712082, 0.11097560077905655, 0.11176573485136032, 0.12275642156600952, 0.1316351592540741, 0.1122269555926323, 0.10429366677999496, 0.10493595898151398, 0.10462617129087448, 0.1031612902879715, 0.10349740833044052, 0.11613216251134872, 0.10005954653024673, 0.0943395271897316, 0.10268396139144897, 0.09872923791408539, 0.09794341772794724, 0.0954003781080246, 0.0921235904097557, 0.09103935211896896, 0.09559633582830429, 0.09700071066617966, 0.09121493250131607]
# validation_loss = [0.2240622341632843, 0.19732463359832764, 0.1789064109325409, 0.17578808963298798, 0.154292032122612, 0.1611149162054062, 0.14089202880859375, 0.139750674366951, 0.14552706480026245, 0.13670943677425385, 0.13881085813045502, 0.13783197104930878, 0.1346522569656372, 0.12376093864440918, 0.13462211191654205, 0.1405389904975891, 0.12351037561893463, 0.12564091384410858, 0.11667536944150925, 0.12569577991962433, 0.11953786760568619, 0.12069004029035568, 0.11339230835437775, 0.1094268187880516, 0.11530520021915436, 0.10314800590276718, 0.10299958288669586, 0.12183269113302231, 0.10612791031599045, 0.12378405779600143, 0.10050586611032486, 0.09495419263839722, 0.10888276249170303, 0.10255566984415054, 0.09371793270111084, 0.10175665467977524, 0.10021286457777023, 0.09558337181806564, 0.09175396710634232, 0.10524248331785202, 0.10370030254125595, 0.097086600959301, 0.09670194983482361, 0.09385593980550766, 0.09643204510211945, 0.08555766195058823, 0.09132998436689377, 0.10222214460372925]

training_loss = [0.6436697244644165, 0.6069275140762329, 0.5468716025352478, 0.5383855700492859, 0.5316725969314575, 0.4743984639644623, 0.4672381579875946, 0.46294933557510376, 0.4431399405002594, 0.43058934807777405, 0.4317863881587982, 0.4263792634010315, 0.42099735140800476, 0.3993827998638153, 0.39957329630851746, 0.39738935232162476, 0.390286386013031, 0.39516064524650574, 0.38762974739074707, 0.3903934061527252, 0.37622058391571045, 0.3738344609737396, 
0.3727012574672699, 0.38065671920776367, 0.36680927872657776, 0.37224236130714417, 0.3615581691265106, 0.3588012158870697, 0.3617861568927765, 0.3566823899745941, 0.36077284812927246, 0.3581610321998596, 0.3568421006202698, 0.3424644470214844, 
0.3552132546901703, 0.3437111973762512, 0.34414955973625183, 0.34148070216178894, 0.3455064594745636, 0.3345792591571808, 0.3306381106376648, 0.3345690369606018, 0.33215346932411194, 0.3232897222042084, 0.32844671607017517, 0.33116838335990906, 0.32888227701187134, 0.32887163758277893]
validation_loss = [0.6250562071800232, 0.5996620059013367, 0.5717889666557312, 0.48972102999687195, 0.5070548057556152, 0.4625944197177887, 0.4787590503692627, 0.4548373818397522, 0.44764500856399536, 0.4232254922389984, 0.40946027636528015, 0.41941627860069275, 0.4231836795806885, 0.3958750367164612, 0.4100712239742279, 0.38357487320899963, 0.40176254510879517, 0.38711827993392944, 0.39841094613075256, 0.39083966612815857, 0.3967365026473999, 0.37259435653686523, 0.38707298040390015, 0.3800281286239624, 0.3753107786178589, 0.3503651022911072, 0.36807793378829956, 0.33819058537483215, 0.36883142590522766, 0.3620303273200989, 0.3626074492931366, 0.324942022562027, 0.3426704406738281, 0.36022400856018066, 0.34678685665130615, 0.3528904914855957, 0.3588217496871948, 0.3489328920841217, 0.3487227261066437, 0.35530170798301697, 0.33454132080078125, 0.3441348671913147, 0.3384690582752228, 0.3338325321674347, 0.34049904346466064, 0.3267683684825897, 0.3382013440132141, 0.34002476930618286]
# Assuming each point corresponds to an epoch or iteration
epochs = range(1, len(training_loss) + 1) 

plt.figure(figsize=(10, 6)) # Create a figure and set its size
plt.plot(epochs, training_loss, label='Training Loss', color='blue') # Plot training loss with blue color
plt.plot(epochs, validation_loss, label='Validation Loss', color='red') # Plot validation loss with red color

plt.title('Training and Validation Loss over Epochs') # Add title to the graph
plt.xlabel('Epochs') # Label the x-axis
plt.ylabel('Loss') # Label the y-axis
plt.legend() # Display the legend to identify the lines
plt.grid(True) # Add a grid for better readability
plt.savefig("fog.png")
# plt.show() # Display the plot